{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0306 15:30:17.255444 13692 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "W0306 15:30:29.122478 13692 deprecation.py:506] From <ipython-input-1-e0db1fbca056>:63: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0306 15:30:29.134446 13692 deprecation.py:323] From c:\\ProgramData\\Anaconda3\\envs\\tf_gpu-1.15\\lib\\site-packages\\tensorflow_core\\contrib\\layers\\python\\layers\\layers.py:1866: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "W0306 15:30:29.184312 13692 deprecation.py:323] From <ipython-input-1-e0db1fbca056>:73: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "W0306 15:30:29.210448 13692 deprecation.py:323] From c:\\ProgramData\\Anaconda3\\envs\\tf_gpu-1.15\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n",
      "\n",
      "Epoch: 100: Error: 11.644104\n",
      "Epoch: 200: Error: 11.542737\n",
      "Epoch: 300: Error: 11.207150\n",
      "Epoch: 400: Error: 10.923779\n",
      "Epoch: 500: Error: 10.682984\n",
      "Epoch: 600: Error: 10.451481\n",
      "Epoch: 700: Error: 10.207722\n",
      "Epoch: 800: Error: 9.995956\n",
      "Epoch: 900: Error: 9.775217\n",
      "Epoch: 1000: Error: 9.605818\n",
      "Epoch: 1100: Error: 9.382044\n",
      "Epoch: 1200: Error: 9.171861\n",
      "Epoch: 1300: Error: 8.989158\n",
      "Epoch: 1400: Error: 8.821529\n",
      "Epoch: 1500: Error: 8.619400\n",
      "Epoch: 1600: Error: 8.469907\n",
      "Epoch: 1700: Error: 8.250780\n",
      "Epoch: 1800: Error: 8.061043\n",
      "Epoch: 1900: Error: 7.919940\n",
      "Epoch: 2000: Error: 7.757402\n",
      "Epoch: 2100: Error: 7.608390\n",
      "Epoch: 2200: Error: 7.423360\n",
      "Epoch: 2300: Error: 7.313856\n",
      "Epoch: 2400: Error: 7.138878\n",
      "Epoch: 2500: Error: 7.024891\n",
      "Epoch: 2600: Error: 6.885193\n",
      "Epoch: 2700: Error: 6.750495\n",
      "Epoch: 2800: Error: 6.622130\n",
      "Epoch: 2900: Error: 6.498282\n",
      "Epoch: 3000: Error: 6.353224\n",
      "Epoch: 3100: Error: 6.217567\n",
      "Epoch: 3200: Error: 6.081306\n",
      "Epoch: 3300: Error: 6.057098\n",
      "Epoch: 3400: Error: 5.921992\n",
      "Epoch: 3500: Error: 5.820321\n",
      "Epoch: 3600: Error: 5.699549\n",
      "Epoch: 3700: Error: 5.613130\n",
      "Epoch: 3800: Error: 5.522909\n",
      "Epoch: 3900: Error: 5.400433\n",
      "Epoch: 4000: Error: 5.326197\n",
      "Epoch: 4100: Error: 5.262822\n",
      "Epoch: 4200: Error: 5.200861\n",
      "Epoch: 4300: Error: 5.095560\n",
      "Epoch: 4400: Error: 5.070072\n",
      "Epoch: 4500: Error: 4.948441\n",
      "Epoch: 4600: Error: 4.956433\n",
      "Epoch: 4700: Error: 4.799186\n",
      "Epoch: 4800: Error: 4.831178\n",
      "Epoch: 4900: Error: 4.686529\n",
      "Epoch: 5000: Error: 4.631902\n",
      "Epoch: 5100: Error: 4.613126\n",
      "Epoch: 5200: Error: 4.545711\n",
      "Epoch: 5300: Error: 4.514168\n",
      "Epoch: 5400: Error: 4.460621\n",
      "Epoch: 5500: Error: 4.463259\n",
      "Epoch: 5600: Error: 4.355303\n",
      "Epoch: 5700: Error: 4.315330\n",
      "Epoch: 5800: Error: 4.283102\n",
      "Epoch: 5900: Error: 4.211460\n",
      "Epoch: 6000: Error: 4.242428\n",
      "Epoch: 6100: Error: 4.158186\n",
      "Epoch: 6200: Error: 4.113731\n",
      "Epoch: 6300: Error: 4.079175\n",
      "Epoch: 6400: Error: 4.040042\n",
      "Epoch: 6500: Error: 4.008620\n",
      "Epoch: 6600: Error: 3.971733\n",
      "Epoch: 6700: Error: 3.926122\n",
      "Epoch: 6800: Error: 3.890327\n",
      "Epoch: 6900: Error: 3.849073\n",
      "Epoch: 7000: Error: 3.796154\n",
      "Epoch: 7100: Error: 3.795875\n",
      "Epoch: 7200: Error: 3.762195\n",
      "Epoch: 7300: Error: 3.665550\n",
      "Epoch: 7400: Error: 3.679387\n",
      "Epoch: 7500: Error: 3.622468\n",
      "Epoch: 7600: Error: 3.553579\n",
      "Epoch: 7700: Error: 3.509136\n",
      "Epoch: 7800: Error: 3.493851\n",
      "Epoch: 7900: Error: 3.424765\n",
      "Epoch: 8000: Error: 3.392050\n",
      "Epoch: 8100: Error: 3.399117\n",
      "Epoch: 8200: Error: 3.322981\n",
      "Epoch: 8300: Error: 3.328838\n",
      "Epoch: 8400: Error: 3.262265\n",
      "Epoch: 8500: Error: 3.211484\n",
      "Epoch: 8600: Error: 3.199052\n",
      "Epoch: 8700: Error: 3.122943\n",
      "Epoch: 8800: Error: 3.122588\n",
      "Epoch: 8900: Error: 3.054740\n",
      "Epoch: 9000: Error: 3.068591\n",
      "Epoch: 9100: Error: 2.975327\n",
      "Epoch: 9200: Error: 2.956582\n",
      "Epoch: 9300: Error: 2.924639\n",
      "Epoch: 9400: Error: 2.899101\n",
      "Epoch: 9500: Error: 2.857295\n",
      "Epoch: 9600: Error: 2.836387\n",
      "Epoch: 9700: Error: 2.822779\n",
      "Epoch: 9800: Error: 2.794581\n",
      "Epoch: 9900: Error: 2.743460\n",
      "Epoch: 10000: Error: 2.688123\n",
      "Epoch: 10100: Error: 2.653805\n",
      "Epoch: 10200: Error: 2.599209\n",
      "Epoch: 10300: Error: 2.584946\n",
      "Epoch: 10400: Error: 2.588525\n",
      "Epoch: 10500: Error: 2.525880\n",
      "Epoch: 10600: Error: 2.495322\n",
      "Epoch: 10700: Error: 2.457884\n",
      "Epoch: 10800: Error: 2.433545\n",
      "Epoch: 10900: Error: 2.459471\n",
      "Epoch: 11000: Error: 2.337549\n",
      "Epoch: 11100: Error: 2.323689\n",
      "Epoch: 11200: Error: 2.340010\n",
      "Epoch: 11300: Error: 2.274051\n",
      "Epoch: 11400: Error: 2.231473\n",
      "Epoch: 11500: Error: 2.198331\n",
      "Epoch: 11600: Error: 2.203743\n",
      "Epoch: 11700: Error: 2.163882\n",
      "Epoch: 11800: Error: 2.122605\n",
      "Epoch: 11900: Error: 2.098187\n",
      "Epoch: 12000: Error: 2.048138\n",
      "Epoch: 12100: Error: 2.023598\n",
      "Epoch: 12200: Error: 1.996908\n",
      "Epoch: 12300: Error: 1.965273\n",
      "Epoch: 12400: Error: 1.934763\n",
      "Epoch: 12500: Error: 1.926604\n",
      "Epoch: 12600: Error: 1.870283\n",
      "Epoch: 12700: Error: 1.850324\n",
      "Epoch: 12800: Error: 1.829759\n",
      "Epoch: 12900: Error: 1.807899\n",
      "Epoch: 13000: Error: 1.769855\n",
      "Epoch: 13100: Error: 1.738607\n",
      "Epoch: 13200: Error: 1.734525\n",
      "Epoch: 13300: Error: 1.710760\n",
      "Epoch: 13400: Error: 1.658137\n",
      "Epoch: 13500: Error: 1.650534\n",
      "Epoch: 13600: Error: 1.617280\n",
      "Epoch: 13700: Error: 1.585054\n",
      "Epoch: 13800: Error: 1.561667\n",
      "Epoch: 13900: Error: 1.547311\n",
      "Epoch: 14000: Error: 1.527428\n",
      "Epoch: 14100: Error: 1.503154\n",
      "Epoch: 14200: Error: 1.475685\n",
      "Epoch: 14300: Error: 1.464963\n",
      "Epoch: 14400: Error: 1.430331\n",
      "Epoch: 14500: Error: 1.401969\n",
      "Epoch: 14600: Error: 1.368478\n",
      "Epoch: 14700: Error: 1.344841\n",
      "Epoch: 14800: Error: 1.320765\n",
      "Epoch: 14900: Error: 1.301118\n",
      "Epoch: 15000: Error: 1.279837\n",
      "Epoch: 15100: Error: 1.246477\n",
      "Epoch: 15200: Error: 1.237370\n",
      "Epoch: 15300: Error: 1.208654\n",
      "Epoch: 15400: Error: 1.198937\n",
      "Epoch: 15500: Error: 1.170437\n",
      "Epoch: 15600: Error: 1.135639\n",
      "Epoch: 15700: Error: 1.123079\n",
      "Epoch: 15800: Error: 1.111868\n",
      "Epoch: 15900: Error: 1.074872\n",
      "Epoch: 16000: Error: 1.070078\n",
      "Epoch: 16100: Error: 1.043565\n",
      "Epoch: 16200: Error: 1.023814\n",
      "Epoch: 16300: Error: 0.998721\n",
      "Epoch: 16400: Error: 0.985302\n",
      "Epoch: 16500: Error: 0.963656\n",
      "Epoch: 16600: Error: 0.949360\n",
      "Epoch: 16700: Error: 0.928229\n",
      "Epoch: 16800: Error: 0.911562\n",
      "Epoch: 16900: Error: 0.892637\n",
      "Epoch: 17000: Error: 0.867420\n",
      "Epoch: 17100: Error: 0.847266\n",
      "Epoch: 17200: Error: 0.843134\n",
      "Epoch: 17300: Error: 0.817953\n",
      "Epoch: 17400: Error: 0.807337\n",
      "Epoch: 17500: Error: 0.776089\n",
      "Epoch: 17600: Error: 0.763159\n",
      "Epoch: 17700: Error: 0.748365\n",
      "Epoch: 17800: Error: 0.737246\n",
      "Epoch: 17900: Error: 0.716635\n",
      "Epoch: 18000: Error: 0.693220\n",
      "Epoch: 18100: Error: 0.687454\n",
      "Epoch: 18200: Error: 0.663857\n",
      "Epoch: 18300: Error: 0.647317\n",
      "Epoch: 18400: Error: 0.635961\n",
      "Epoch: 18500: Error: 0.620090\n",
      "Epoch: 18600: Error: 0.596790\n",
      "Epoch: 18700: Error: 0.591565\n",
      "Epoch: 18800: Error: 0.578610\n",
      "Epoch: 18900: Error: 0.554059\n",
      "Epoch: 19000: Error: 0.547043\n",
      "Epoch: 19100: Error: 0.526933\n",
      "Epoch: 19200: Error: 0.523861\n",
      "Epoch: 19300: Error: 0.503989\n",
      "Epoch: 19400: Error: 0.488586\n",
      "Epoch: 19500: Error: 0.472223\n",
      "Epoch: 19600: Error: 0.462872\n",
      "Epoch: 19700: Error: 0.449378\n",
      "Epoch: 19800: Error: 0.433154\n",
      "Epoch: 19900: Error: 0.428182\n",
      "Epoch: 20000: Error: 0.410838\n",
      "Epoch: 20100: Error: 0.400767\n",
      "Epoch: 20200: Error: 0.391168\n",
      "Epoch: 20300: Error: 0.380082\n",
      "Epoch: 20400: Error: 0.367501\n",
      "Epoch: 20500: Error: 0.354932\n",
      "Epoch: 20600: Error: 0.344170\n",
      "Epoch: 20700: Error: 0.333998\n",
      "Epoch: 20800: Error: 0.326283\n",
      "Epoch: 20900: Error: 0.320185\n",
      "Epoch: 21000: Error: 0.302530\n",
      "Epoch: 21100: Error: 0.292826\n",
      "Epoch: 21200: Error: 0.282609\n",
      "Epoch: 21300: Error: 0.276962\n",
      "Epoch: 21400: Error: 0.267772\n",
      "Epoch: 21500: Error: 0.253560\n",
      "Epoch: 21600: Error: 0.247936\n",
      "Epoch: 21700: Error: 0.237728\n",
      "Epoch: 21800: Error: 0.227874\n",
      "Epoch: 21900: Error: 0.220206\n",
      "Epoch: 22000: Error: 0.213410\n",
      "Epoch: 22100: Error: 0.204280\n",
      "Epoch: 22200: Error: 0.196435\n",
      "Epoch: 22300: Error: 0.188376\n",
      "Epoch: 22400: Error: 0.183288\n",
      "Epoch: 22500: Error: 0.173354\n",
      "Epoch: 22600: Error: 0.168379\n",
      "Epoch: 22700: Error: 0.160511\n",
      "Epoch: 22800: Error: 0.152635\n",
      "Epoch: 22900: Error: 0.149153\n",
      "Epoch: 23000: Error: 0.141541\n",
      "Epoch: 23100: Error: 0.132637\n",
      "Epoch: 23200: Error: 0.126391\n",
      "Epoch: 23300: Error: 0.121970\n",
      "Epoch: 23400: Error: 0.116805\n",
      "Epoch: 23500: Error: 0.109908\n",
      "Epoch: 23600: Error: 0.105292\n",
      "Epoch: 23700: Error: 0.100729\n",
      "Epoch: 23800: Error: 0.095513\n",
      "Epoch: 23900: Error: 0.090521\n",
      "Epoch: 24000: Error: 0.086216\n",
      "Epoch: 24100: Error: 0.081038\n",
      "Epoch: 24200: Error: 0.077272\n",
      "Epoch: 24300: Error: 0.072570\n",
      "Epoch: 24400: Error: 0.068611\n",
      "Epoch: 24500: Error: 0.064675\n",
      "Epoch: 24600: Error: 0.059914\n",
      "Epoch: 24700: Error: 0.057145\n",
      "Epoch: 24800: Error: 0.052946\n",
      "Epoch: 24900: Error: 0.050277\n",
      "Epoch: 25000: Error: 0.046929\n",
      "Epoch: 25100: Error: 0.044066\n",
      "Epoch: 25200: Error: 0.041042\n",
      "Epoch: 25300: Error: 0.038522\n",
      "Epoch: 25400: Error: 0.035955\n",
      "Epoch: 25500: Error: 0.033423\n",
      "Epoch: 25600: Error: 0.030616\n",
      "Epoch: 25700: Error: 0.028564\n",
      "Epoch: 25800: Error: 0.026862\n",
      "Epoch: 25900: Error: 0.024663\n",
      "Epoch: 26000: Error: 0.022764\n",
      "Epoch: 26100: Error: 0.021171\n",
      "Epoch: 26200: Error: 0.019356\n",
      "Epoch: 26300: Error: 0.017917\n",
      "Epoch: 26400: Error: 0.016307\n",
      "Epoch: 26500: Error: 0.014998\n",
      "Epoch: 26600: Error: 0.013746\n",
      "Epoch: 26700: Error: 0.012767\n",
      "Epoch: 26800: Error: 0.011479\n",
      "Epoch: 26900: Error: 0.010650\n",
      "Epoch: 27000: Error: 0.009649\n",
      "Epoch: 27100: Error: 0.008929\n",
      "Epoch: 27200: Error: 0.008202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27300: Error: 0.007559\n",
      "Epoch: 27400: Error: 0.006954\n",
      "Epoch: 27500: Error: 0.006271\n",
      "Epoch: 27600: Error: 0.005702\n",
      "Epoch: 27700: Error: 0.005263\n",
      "Epoch: 27800: Error: 0.004737\n",
      "Epoch: 27900: Error: 0.004401\n",
      "Epoch: 28000: Error: 0.004045\n",
      "Epoch: 28100: Error: 0.003733\n",
      "Epoch: 28200: Error: 0.003508\n",
      "Epoch: 28300: Error: 0.003284\n",
      "Epoch: 28400: Error: 0.003140\n",
      "Epoch: 28500: Error: 0.002956\n",
      "Epoch: 28600: Error: 0.002899\n",
      "Epoch: 28700: Error: 0.002604\n",
      "Epoch: 28800: Error: 0.002038\n",
      "Epoch: 28900: Error: 0.002205\n",
      "Epoch: 29000: Error: 0.002170\n",
      "Epoch: 29100: Error: 0.001238\n",
      "Epoch: 29200: Error: 0.001880\n",
      "Epoch: 29300: Error: 0.001821\n",
      "Epoch: 29400: Error: 0.001064\n",
      "Epoch: 29500: Error: 0.001818\n",
      "Epoch: 29600: Error: 0.001672\n",
      "Epoch: 29700: Error: 0.001299\n",
      "Epoch: 29800: Error: 0.001574\n",
      "Epoch: 29900: Error: 0.001509\n",
      "Epoch: 30000: Error: 0.001953\n",
      "Epoch: 30100: Error: 0.001210\n",
      "Epoch: 30200: Error: 0.001952\n",
      "Epoch: 30300: Error: 0.001104\n",
      "Epoch: 30400: Error: 0.000987\n",
      "Epoch: 30500: Error: 0.000966\n",
      "Epoch: 30600: Error: 0.000807\n",
      "Epoch: 30700: Error: 0.000700\n",
      "Epoch: 30800: Error: 0.000700\n",
      "Converged.\n",
      "Test error:  0.00015792072\n",
      "Maximum percentage error: 33.376620\n",
      "Average percentage error: 0.669821\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "\n",
    "\n",
    "def getData():\n",
    "    with open('process/process_file_8.csv') as csv_file:\n",
    "        reader = csv.reader(csv_file)\n",
    "        data = list(reader)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def preprocessData(data):\n",
    "    one_hot_encoder = preprocessing.OneHotEncoder()\n",
    "\n",
    "    processed_data = one_hot_encoder.fit_transform(data[:, 0:2]).toarray()\n",
    "    processed_data = np.append(processed_data, data[:, 2:6], 1)\n",
    "\n",
    "    processed_data = preprocessing.normalize(processed_data)\n",
    "    np.random.shuffle(processed_data)\n",
    "\n",
    "    return processed_data\n",
    "\n",
    "\n",
    "def learn(data):\n",
    "    data = preprocessData(data)\n",
    "    num_params = data.shape[1] - 1\n",
    "\n",
    "    X = data[:, 0:num_params]\n",
    "    Y = data[:, num_params].reshape(-1, 1)\n",
    "\n",
    "    # Split the data into training and testing sets (70/30)\n",
    "    train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=0.30)\n",
    "    train_opening_price = train_X[:, num_params - 1].reshape(-1, 1)\n",
    "    test_opening_price = test_X[:, num_params - 1].reshape(-1, 1)\n",
    "\n",
    "    # Get the initial stock prices for computing the relative cost\n",
    "    stock_data = tf.placeholder(tf.float32, [None, num_params])\n",
    "    opening_price = tf.placeholder(tf.float32, [None, 1])\n",
    "    stock_price = tf.placeholder(tf.float32, [None, 1])\n",
    "\n",
    "    # Number of neurons in the hidden layer\n",
    "    n_hidden_1 = 3\n",
    "    n_hidden_2 = 3\n",
    "\n",
    "    weights = {\n",
    "        'out': tf.Variable(tf.random_normal([n_hidden_2, 1]))\n",
    "    }\n",
    "    biases = {\n",
    "        'out': tf.Variable(tf.random_normal([1]))\n",
    "    }\n",
    "\n",
    "    # Implement dropout to reduce overfitting\n",
    "    keep_prob_input = tf.placeholder(tf.float32)\n",
    "    keep_prob_hidden = tf.placeholder(tf.float32)\n",
    "\n",
    "    # Hidden layers\n",
    "    input_dropout = tf.nn.dropout(stock_data, keep_prob_input)\n",
    "    layer_1 = slim.fully_connected(input_dropout, n_hidden_1, biases_initializer=None, activation_fn=tf.nn.relu)\n",
    "    layer_1_dropout = tf.nn.dropout(layer_1, keep_prob_hidden)\n",
    "    layer_2 = slim.fully_connected(input_dropout, n_hidden_1, biases_initializer=None, activation_fn=tf.nn.relu)\n",
    "    layer_2_dropout = tf.nn.dropout(layer_2, keep_prob_hidden)\n",
    "    # regression  layer = (w'x+b)\n",
    "\n",
    "    output_layer = tf.add(tf.matmul(layer_2_dropout, weights['out']), biases['out'])\n",
    "\n",
    "    learning_rate = 1e-4\n",
    "    cost_function = tf.reduce_mean(tf.pow(tf.div(tf.subtract(stock_price, output_layer), opening_price), 2))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost_function)\n",
    "\n",
    "    last_cost = 0\n",
    "    tolerance = 1e-6\n",
    "    epochs = 1\n",
    "    max_epochs = 1e6\n",
    "\n",
    "    config = tf.ConfigProto(log_device_placement = True)\n",
    "    sess = tf.Session(config=config)\n",
    "    with sess:\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "\n",
    "        history = []\n",
    "        while True:\n",
    "            sess.run(optimizer,\n",
    "                     feed_dict={stock_data: train_X, opening_price: train_opening_price, stock_price: train_Y,\n",
    "                                keep_prob_input: 0.8, keep_prob_hidden: 0.5})\n",
    "\n",
    "            if epochs % 100 == 0:\n",
    "                cost = sess.run(cost_function, feed_dict={stock_data: train_X, opening_price: train_opening_price,\n",
    "                                                          stock_price: train_Y, keep_prob_input: 0.8,\n",
    "                                                          keep_prob_hidden: 0.5})\n",
    "                history.append(cost)\n",
    "                print(\"Epoch: %d: Error: %f\" % (epochs, cost))\n",
    "\n",
    "                if abs(cost - last_cost) <= tolerance or epochs > max_epochs:\n",
    "                    print(\"Converged.\")\n",
    "                    break\n",
    "                last_cost = cost\n",
    "\n",
    "            epochs += 1\n",
    "\n",
    "        print(\"Test error: \", sess.run(cost_function, feed_dict={stock_data: test_X, opening_price: test_opening_price,\n",
    "                                                                 stock_price: test_Y, keep_prob_input: 1.0,\n",
    "                                                                 keep_prob_hidden: 1.0}))\n",
    "        test_results = sess.run(output_layer, feed_dict={stock_data: test_X, stock_price: test_Y, keep_prob_input: 1.0,\n",
    "                                                         keep_prob_hidden: 1.0})\n",
    "\n",
    "    avg_perc_error = 0\n",
    "    max_perc_error = 0\n",
    "    mei = 0\n",
    "    for i in range(len(test_Y)):\n",
    "        actual_change = abs(test_Y[i][0] - test_X[i][num_params - 1]) / test_X[i][num_params - 1]\n",
    "        predicted_change = abs(test_results[i][0] - test_X[i][num_params - 1]) / test_X[i][num_params - 1]\n",
    "        delta = abs(actual_change - predicted_change)\n",
    "        avg_perc_error = avg_perc_error + delta\n",
    "        if delta > max_perc_error:\n",
    "            max_perc_error = delta\n",
    "            mei = i\n",
    "\n",
    "    avg_perc_error = (avg_perc_error * 100) / len(test_Y)\n",
    "    max_perc_error *= 100\n",
    "    print(\"Maximum percentage error: %f\\nAverage percentage error: %f\\n\" % (max_perc_error, avg_perc_error))\n",
    "\n",
    "\n",
    "def main():\n",
    "    data = np.array(getData())\n",
    "    learn(data)\n",
    "\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
