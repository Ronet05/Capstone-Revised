{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "from tensorflow.keras import Model, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData():\n",
    "    with open('process/process_file_3.csv') as csv_file:\n",
    "        reader = csv.reader(csv_file)\n",
    "        data = list(reader)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def preprocessData(data):\n",
    "    one_hot_encoder = preprocessing.OneHotEncoder()\n",
    "\n",
    "    processed_data = one_hot_encoder.fit_transform(data[:, 0:2]).toarray()\n",
    "    processed_data = np.append(processed_data, data[:, 2:6], 1)\n",
    "\n",
    "    processed_data = preprocessing.normalize(processed_data)\n",
    "    np.random.shuffle(processed_data)\n",
    "\n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn(data):\n",
    "    data = preprocessData(data)\n",
    "    num_params = data.shape[1] - 1\n",
    "\n",
    "    X = data[:, 0:num_params]\n",
    "    Y = data[:, num_params].reshape(-1, 1)\n",
    "\n",
    "    # Split the data into training and testing sets (70/30)\n",
    "    train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=0.30)\n",
    "    train_opening_price = train_X[:, num_params - 1].reshape(-1, 1)\n",
    "    test_opening_price = test_X[:, num_params - 1].reshape(-1, 1)\n",
    "    \n",
    "    # Get the initial stock prices for computing the relative cost\n",
    "    stock_data = tf.placeholder(tf.float32, [None, num_params])\n",
    "    opening_price = tf.placeholder(tf.float32, [None, 1])\n",
    "    stock_price = tf.placeholder(tf.float32, [None, 1])\n",
    "\n",
    "    # Number of neurons in the hidden layer\n",
    "    n_hidden_1 = 3\n",
    "    n_hidden_2 = 3\n",
    "\n",
    "    weights = {\n",
    "        'out': tf.Variable(tf.random_normal([n_hidden_2, 1]))\n",
    "    }\n",
    "    biases = {\n",
    "        'out': tf.Variable(tf.random_normal([1]))\n",
    "    }\n",
    "\n",
    "    # Implement dropout to reduce overfitting\n",
    "    keep_prob_input = tf.placeholder(tf.float32)\n",
    "    keep_prob_hidden = tf.placeholder(tf.float32)\n",
    "    \n",
    "    #layers\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(layers.Conv1D(filters = 32, kernel_size = 3, acitvation = 'relu', input_shape = ()))\n",
    "    model.add(layers.MaxPool1D(2))\n",
    "    model.add(layers.Conv1D(filters = 64, kernel_size = 3, activation = 'relu'))\n",
    "    model.add(layers.MaxPool1D(2))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(3, activation = 'relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(3, activation = 'relu'))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Dense(1))\n",
    "    \n",
    "    output_layer = tf.add(tf.matmul(model.output_layer, weights['out']), biases['out'])\n",
    "    cost_function = tf.reduce_mean(tf.pow(tf.div(tf.subtract(stock_price, output_layer), opening_price), 2))\n",
    "    optimizers = tf.train.AdamOptimizer(learning_rate).minimize(cost_function)\n",
    "    \n",
    "    model.compile(optimizer = optimizers, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 14898, 755, 32)    320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 7449, 377, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 7447, 375, 64)     18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 3723, 187, 64)     0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 44556864)          0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3)                 133670595 \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 133,689,423\n",
      "Trainable params: 133,689,423\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(layers.Conv2D(filters = 32, kernel_size = 3, activation = 'relu', input_shape = (14900, 757, 1)))\n",
    "model.add(layers.MaxPool2D(2))\n",
    "model.add(layers.Conv2D(filters = 64, kernel_size = 3, activation = 'relu'))\n",
    "model.add(layers.MaxPool2D(2))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(3, activation = 'relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(3, activation = 'relu'))\n",
    "model.add(layers.Dropout(0.3))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn(data):\n",
    "    data = preprocessData(data)\n",
    "    num_params = data.shape[1] - 1\n",
    "\n",
    "    X = data[:, 0:num_params]\n",
    "    Y = data[:, num_params].reshape(-1, 1)\n",
    "\n",
    "    # Split the data into training and testing sets (70/30)\n",
    "    train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=0.30)\n",
    "    train_opening_price = train_X[:, num_params - 1].reshape(-1, 1)\n",
    "    test_opening_price = test_X[:, num_params - 1].reshape(-1, 1)\n",
    "    \n",
    "    # Get the initial stock prices for computing the relative cost\n",
    "    stock_data = tf.placeholder(tf.float32, [None, num_params])\n",
    "    opening_price = tf.placeholder(tf.float32, [None, 1])\n",
    "    stock_price = tf.placeholder(tf.float32, [None, 1])\n",
    "\n",
    "    # Number of neurons in the hidden layer\n",
    "    n_hidden_1 = 3\n",
    "    n_hidden_2 = 3\n",
    "\n",
    "    weights = {\n",
    "        'out': tf.Variable(tf.random_normal([n_hidden_2, 1]))\n",
    "    }\n",
    "    biases = {\n",
    "        'out': tf.Variable(tf.random_normal([1]))\n",
    "    }\n",
    "\n",
    "    # Implement dropout to reduce overfitting\n",
    "    keep_prob_input = tf.placeholder(tf.float32)\n",
    "    keep_prob_hidden = tf.placeholder(tf.float32)\n",
    "\n",
    "    # Hidden layers\n",
    "    input_dropout = tf.nn.dropout(stock_data, keep_prob_input)\n",
    "    conv_l1 = slim.conv1d(input_dropout, 32, 3, activation_fn = tf.nn.relu)\n",
    "    maxpool_l1 = tf.nn.max_pool1d(conv_l1, 2)\n",
    "    conv_l2 = slim.conv1d(maxpool_l1, 64, 3, activation_fn = tf.nn.relu)\n",
    "    maxpool_l2 = tf.nn.max_pool1d(conv_l2, 2)\n",
    "    flatten = tf.nn.flatten(maxpool_l2)\n",
    "    layer_1 = slim.fully_connected(flatten, n_hidden_1, biases_initializer=None, activation_fn=tf.nn.relu)\n",
    "    layer_1_dropout = tf.nn.dropout(layer_1, keep_prob_hidden)\n",
    "    layer_2 = slim.fully_connected(input_dropout, n_hidden_1, biases_initializer=None, activation_fn=tf.nn.relu)\n",
    "    layer_2_dropout = tf.nn.dropout(layer_2, keep_prob_hidden)\n",
    "    \n",
    "    # regression  layer = (w'x+b)\n",
    "    output_layer = tf.add(tf.matmul(layer_2_dropout, weights['out']), biases['out'])\n",
    "\n",
    "    learning_rate = 1e-4\n",
    "    cost_function = tf.reduce_mean(tf.pow(tf.div(tf.subtract(stock_price, output_layer), opening_price), 2))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost_function)\n",
    "\n",
    "    last_cost = 0\n",
    "    tolerance = 1e-6\n",
    "    epochs = 1\n",
    "    max_epochs = 15000\n",
    "\n",
    "    config = tf.ConfigProto(log_device_placement = True)\n",
    "    sess = tf.Session(config=config)\n",
    "    with sess:\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "\n",
    "        history = []\n",
    "        while True:\n",
    "            sess.run(optimizer,\n",
    "                     feed_dict={stock_data: train_X.reshape(train_X.shape+(1,)), opening_price: train_opening_price, stock_price: train_Y,\n",
    "                                keep_prob_input: 0.8, keep_prob_hidden: 0.5})\n",
    "\n",
    "            if epochs % 100 == 0:\n",
    "                cost = sess.run(cost_function, feed_dict={stock_data: train_X, opening_price: train_opening_price,\n",
    "                                                          stock_price: train_Y, keep_prob_input: 0.8,\n",
    "                                                          keep_prob_hidden: 0.5})\n",
    "                history.append(cost)\n",
    "                print(\"Epoch: %d: Error: %f\" % (epochs, cost))\n",
    "\n",
    "                if abs(cost - last_cost) <= tolerance or epochs > max_epochs:\n",
    "                    print(\"Converged.\")\n",
    "                    break\n",
    "                last_cost = cost\n",
    "\n",
    "            epochs += 1\n",
    "\n",
    "        print(\"Test error: \", sess.run(cost_function, feed_dict={stock_data: test_X.reshape(test_X.shape+(1,)), opening_price: test_opening_price,\n",
    "                                                                 stock_price: test_Y, keep_prob_input: 1.0,\n",
    "                                                                 keep_prob_hidden: 1.0}))\n",
    "        test_results = sess.run(output_layer, feed_dict={stock_data: test_X, stock_price: test_Y, keep_prob_input: 1.0,\n",
    "                                                         keep_prob_hidden: 1.0})\n",
    "\n",
    "    avg_perc_error = 0\n",
    "    max_perc_error = 0\n",
    "    mei = 0\n",
    "    for i in range(len(test_Y)):\n",
    "        actual_change = abs(test_Y[i][0] - test_X[i][num_params - 1]) / test_X[i][num_params - 1]\n",
    "        predicted_change = abs(test_results[i][0] - test_X[i][num_params - 1]) / test_X[i][num_params - 1]\n",
    "        delta = abs(actual_change - predicted_change)\n",
    "        avg_perc_error = avg_perc_error + delta\n",
    "        if delta > max_perc_error:\n",
    "            max_perc_error = delta\n",
    "            mei = i\n",
    "\n",
    "    avg_perc_error = (avg_perc_error * 100) / len(test_Y)\n",
    "    max_perc_error *= 100\n",
    "    print(\"Maximum percentage error: %f\\nAverage percentage error: %f\\n\" % (max_perc_error, avg_perc_error))\n",
    "\n",
    "\n",
    "def main():\n",
    "    data = np.array(getData())\n",
    "    learn(data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-49-b38d5027ae1c>:34: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Convolution expects input with rank 3, got 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-49-b38d5027ae1c>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-49-b38d5027ae1c>\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m# Hidden layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0minput_dropout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstock_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mconv_l1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0mmaxpool_l1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_l1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mconv_l2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxpool_l1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu-1.15/lib/python3.7/site-packages/tensorflow_core/contrib/framework/python/ops/arg_scope.py\u001b[0m in \u001b[0;36mfunc_with_args\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m       \u001b[0mcurrent_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_scope\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey_func\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m       \u001b[0mcurrent_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcurrent_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m   \u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu-1.15/lib/python3.7/site-packages/tensorflow_core/contrib/layers/python/layers/layers.py\u001b[0m in \u001b[0;36mconvolution1d\u001b[0;34m(inputs, num_outputs, kernel_size, stride, padding, data_format, rate, activation_fn, normalizer_fn, normalizer_params, weights_initializer, weights_regularizer, biases_initializer, biases_regularizer, reuse, variables_collections, outputs_collections, trainable, scope)\u001b[0m\n\u001b[1;32m   1111\u001b[0m       \u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m       \u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1113\u001b[0;31m       conv_dims=1)\n\u001b[0m\u001b[1;32m   1114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu-1.15/lib/python3.7/site-packages/tensorflow_core/contrib/framework/python/ops/arg_scope.py\u001b[0m in \u001b[0;36mfunc_with_args\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m       \u001b[0mcurrent_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_scope\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey_func\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m       \u001b[0mcurrent_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcurrent_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m   \u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu-1.15/lib/python3.7/site-packages/tensorflow_core/contrib/layers/python/layers/layers.py\u001b[0m in \u001b[0;36mconvolution\u001b[0;34m(inputs, num_outputs, kernel_size, stride, padding, data_format, rate, activation_fn, normalizer_fn, normalizer_params, weights_initializer, weights_regularizer, biases_initializer, biases_regularizer, reuse, variables_collections, outputs_collections, trainable, scope, conv_dims)\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mconv_dims\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconv_dims\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0minput_rank\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       raise ValueError('Convolution expects input with rank %d, got %d' %\n\u001b[0;32m-> 1025\u001b[0;31m                        (conv_dims + 2, input_rank))\n\u001b[0m\u001b[1;32m   1026\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_rank\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m       \u001b[0mlayer_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvolutional_layers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConvolution1D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Convolution expects input with rank 3, got 2"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting closing price\n",
    "#cost fn on opening price \n",
    "\n",
    "data = np.array(getData())\n",
    "data = preprocessData(data)\n",
    "num_params = data.shape[1] - 1\n",
    "\n",
    "X = data[:, 0:num_params]\n",
    "Y = data[:, num_params].reshape(-1, 1)\n",
    "\n",
    "# Split the data into training and testing sets (70/30)\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=0.30)\n",
    "train_opening_price = train_X[:, num_params - 1].reshape(-1, 1)\n",
    "test_opening_price = test_X[:, num_params - 1].reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21286, 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:,num_params].reshape(-1,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "757"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.matrix_rank(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14900, 759, 1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.reshape(train_X.shape+(1,)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14900, 759)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14900"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
