{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0401 13:21:42.631036  9800 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "from tensorflow.keras import Model, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData():\n",
    "    with open('process/process_file_3.csv') as csv_file:\n",
    "        reader = csv.reader(csv_file)\n",
    "        data = list(reader)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def preprocessData(data):\n",
    "    one_hot_encoder = preprocessing.OneHotEncoder()\n",
    "\n",
    "    processed_data = one_hot_encoder.fit_transform(data[:, 0:2]).toarray()\n",
    "    processed_data = np.append(processed_data, data[:, 2:6], 1)\n",
    "\n",
    "    processed_data = preprocessing.normalize(processed_data)\n",
    "    np.random.shuffle(processed_data)\n",
    "\n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn(data):\n",
    "    data = preprocessData(data)\n",
    "    num_params = data.shape[1] - 1\n",
    "\n",
    "    X = data[:, 0:num_params]\n",
    "    Y = data[:, num_params].reshape(-1, 1)\n",
    "\n",
    "    # Split the data into training and testing sets (70/30)\n",
    "    train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=0.30)\n",
    "    train_opening_price = train_X[:, num_params - 1].reshape(-1, 1)\n",
    "    test_opening_price = test_X[:, num_params - 1].reshape(-1, 1)\n",
    "    \n",
    "    # Get the initial stock prices for computing the relative cost\n",
    "    stock_data = tf.placeholder(tf.float32, [None, num_params])\n",
    "    opening_price = tf.placeholder(tf.float32, [None, 1])\n",
    "    stock_price = tf.placeholder(tf.float32, [None, 1])\n",
    "\n",
    "    # Number of neurons in the hidden layer\n",
    "    n_hidden_1 = 3\n",
    "    n_hidden_2 = 3\n",
    "\n",
    "    weights = {\n",
    "        'out': tf.Variable(tf.random_normal([n_hidden_2, 1]))\n",
    "    }\n",
    "    biases = {\n",
    "        'out': tf.Variable(tf.random_normal([1]))\n",
    "    }\n",
    "\n",
    "    # Implement dropout to reduce overfitting\n",
    "    keep_prob_input = tf.placeholder(tf.float32)\n",
    "    keep_prob_hidden = tf.placeholder(tf.float32)\n",
    "    \n",
    "    #layers\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(layers.Conv1D(filters = 32, kernel_size = 3, activation = 'relu', input_shape=np.expand_dims(train_X[0], axis=1).shape))\n",
    "    model.add(layers.MaxPool1D(2))\n",
    "    model.add(layers.Conv1D(filters = 64, kernel_size = 3, activation = 'relu'))\n",
    "    model.add(layers.MaxPool1D(2))\n",
    "    model.add(layers.GlobalAveragePooling1D())\n",
    "    model.add(layers.Dense(3, activation = 'relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(3, activation = 'relu'))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Dense(1, name = 'reg_layer'))\n",
    "    \n",
    "    output_layer = tf.add(tf.matmul(weights['out'],model.get_layer('reg_layer').output), biases['out'])\n",
    "    cost_function = tf.reduce_mean(tf.pow(tf.div(tf.subtract(stock_price, output_layer), opening_price), 2))\n",
    "    optimizers = tf.keras.optimizers.SGD(learning_rate=1e-3, momentum = 0.9).minimize(cost_function, var_list=[weights, biases])\n",
    "    \n",
    "    \n",
    "    model.compile(optimizer = optimizers, loss = tf.pow(tf.div(tf.subtract(stock_price, output_layer), opening_price), metrics = ['acc']))\n",
    "    print(model.summary())\n",
    "    \n",
    "def main():\n",
    "    data = np.array(getData())\n",
    "    learn(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(getData())\n",
    "data = preprocessData(data)\n",
    "num_params = data.shape[1] - 1\n",
    "\n",
    "X = data[:, 0:num_params]\n",
    "Y = data[:, num_params].reshape(-1, 1)\n",
    "\n",
    "# Split the data into training and testing sets (70/30)\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=0.30)\n",
    "train_opening_price = train_X[:, num_params - 1].reshape(-1, 1)\n",
    "test_opening_price = test_X[:, num_params - 1].reshape(-1, 1)\n",
    "\n",
    "# Get the initial stock prices for computing the relative cost\n",
    "stock_data = tf.placeholder(tf.float64, [None, num_params])\n",
    "opening_price = tf.placeholder(tf.float64, [None, 1])\n",
    "stock_price = tf.placeholder(tf.float64, [None, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_8 (Conv1D)            (None, 757, 32)           128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 378, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 376, 64)           6208      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 188, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 12032)             0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 3)                 36099     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 42,451\n",
      "Trainable params: 42,451\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "stock_data = train_X\n",
    "opening_price = train_opening_price\n",
    "stock_price= train_Y\n",
    "\n",
    "\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(layers.Conv1D(filters = 32, kernel_size = 3, activation = 'relu', input_shape = np.expand_dims(train_X[0], axis=1).shape))\n",
    "model.add(layers.MaxPool1D(2))\n",
    "model.add(layers.Conv1D(filters = 64, kernel_size = 3, activation = 'relu'))\n",
    "model.add(layers.MaxPool1D(2))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(3, activation = 'relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(3, activation = 'relu'))\n",
    "model.add(layers.Dropout(0.3))\n",
    "l0= layers.Dense(1)\n",
    "model.add(l0)\n",
    "\n",
    "#loss = tf.pow(tf.div(tf.subtract(stock_price, l0.output), opening_price))\n",
    "model.compile(loss = 'mse', optimizer = tf.keras.optimizers.SGD(lr = 0.001, momentum = 0.9), metrics = ['mse', 'mae'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn(data):\n",
    "    data = preprocessData(data)\n",
    "    num_params = data.shape[1] - 1\n",
    "\n",
    "    X = data[:, 0:num_params]\n",
    "    Y = data[:, num_params].reshape(-1, 1)\n",
    "\n",
    "    # Split the data into training and testing sets (70/30)\n",
    "    train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=0.30)\n",
    "    train_opening_price = train_X[:, num_params - 1].reshape(-1, 1)\n",
    "    test_opening_price = test_X[:, num_params - 1].reshape(-1, 1)\n",
    "    \n",
    "    # Get the initial stock prices for computing the relative cost\n",
    "    stock_data = tf.placeholder(tf.float32, [None, num_params])\n",
    "    opening_price = tf.placeholder(tf.float32, [None, 1])\n",
    "    stock_price = tf.placeholder(tf.float32, [None, 1])\n",
    "\n",
    "    # Number of neurons in the hidden layer\n",
    "    n_hidden_1 = 3\n",
    "    n_hidden_2 = 3\n",
    "\n",
    "    weights = {\n",
    "        'out': tf.Variable(tf.random_normal([n_hidden_2, 1]))\n",
    "    }\n",
    "    biases = {\n",
    "        'out': tf.Variable(tf.random_normal([1]))\n",
    "    }\n",
    "\n",
    "    # Implement dropout to reduce overfitting\n",
    "    keep_prob_input = tf.placeholder(tf.float32)\n",
    "    keep_prob_hidden = tf.placeholder(tf.float32)\n",
    "\n",
    "    # Hidden layers\n",
    "    input_dropout = tf.nn.dropout(stock_data, keep_prob_input)\n",
    "    conv_l1 = slim.conv1d(input_dropout, 32, 3, activation_fn = tf.nn.relu)\n",
    "    maxpool_l1 = tf.nn.max_pool1d(conv_l1, 2)\n",
    "    conv_l2 = slim.conv1d(maxpool_l1, 64, 3, activation_fn = tf.nn.relu)\n",
    "    maxpool_l2 = tf.nn.max_pool1d(conv_l2, 2)\n",
    "    flatten = tf.nn.flatten(maxpool_l2)\n",
    "    layer_1 = slim.fully_connected(flatten, n_hidden_1, biases_initializer=None, activation_fn=tf.nn.relu)\n",
    "    layer_1_dropout = tf.nn.dropout(layer_1, keep_prob_hidden)\n",
    "    layer_2 = slim.fully_connected(input_dropout, n_hidden_1, biases_initializer=None, activation_fn=tf.nn.relu)\n",
    "    layer_2_dropout = tf.nn.dropout(layer_2, keep_prob_hidden)\n",
    "    \n",
    "    # regression  layer = (w'x+b)\n",
    "    output_layer = tf.add(tf.matmul(layer_2_dropout, weights['out']), biases['out'])\n",
    "\n",
    "    learning_rate = 1e-4\n",
    "    cost_function = tf.reduce_mean(tf.pow(tf.div(tf.subtract(stock_price, output_layer), opening_price), 2))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost_function)\n",
    "\n",
    "    last_cost = 0\n",
    "    tolerance = 1e-6\n",
    "    epochs = 1\n",
    "    max_epochs = 15000\n",
    "\n",
    "    config = tf.ConfigProto(log_device_placement = True)\n",
    "    sess = tf.Session(config=config)\n",
    "    with sess:\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "\n",
    "        history = []\n",
    "        while True:\n",
    "            sess.run(optimizer,\n",
    "                     feed_dict={stock_data: train_X.reshape(train_X.shape+(1,)), opening_price: train_opening_price, stock_price: train_Y,\n",
    "                                keep_prob_input: 0.8, keep_prob_hidden: 0.5})\n",
    "\n",
    "            if epochs % 100 == 0:\n",
    "                cost = sess.run(cost_function, feed_dict={stock_data: train_X, opening_price: train_opening_price,\n",
    "                                                          stock_price: train_Y, keep_prob_input: 0.8,\n",
    "                                                          keep_prob_hidden: 0.5})\n",
    "                history.append(cost)\n",
    "                print(\"Epoch: %d: Error: %f\" % (epochs, cost))\n",
    "\n",
    "                if abs(cost - last_cost) <= tolerance or epochs > max_epochs:\n",
    "                    print(\"Converged.\")\n",
    "                    break\n",
    "                last_cost = cost\n",
    "\n",
    "            epochs += 1\n",
    "\n",
    "        print(\"Test error: \", sess.run(cost_function, feed_dict={stock_data: test_X.reshape(test_X.shape+(1,)), opening_price: test_opening_price,\n",
    "                                                                 stock_price: test_Y, keep_prob_input: 1.0,\n",
    "                                                                 keep_prob_hidden: 1.0}))\n",
    "        test_results = sess.run(output_layer, feed_dict={stock_data: test_X, stock_price: test_Y, keep_prob_input: 1.0,\n",
    "                                                         keep_prob_hidden: 1.0})\n",
    "\n",
    "    avg_perc_error = 0\n",
    "    max_perc_error = 0\n",
    "    mei = 0\n",
    "    for i in range(len(test_Y)):\n",
    "        actual_change = abs(test_Y[i][0] - test_X[i][num_params - 1]) / test_X[i][num_params - 1]\n",
    "        predicted_change = abs(test_results[i][0] - test_X[i][num_params - 1]) / test_X[i][num_params - 1]\n",
    "        delta = abs(actual_change - predicted_change)\n",
    "        avg_perc_error = avg_perc_error + delta\n",
    "        if delta > max_perc_error:\n",
    "            max_perc_error = delta\n",
    "            mei = i\n",
    "\n",
    "    avg_perc_error = (avg_perc_error * 100) / len(test_Y)\n",
    "    max_perc_error *= 100\n",
    "    print(\"Maximum percentage error: %f\\nAverage percentage error: %f\\n\" % (max_perc_error, avg_perc_error))\n",
    "\n",
    "\n",
    "def main():\n",
    "    data = np.array(getData())\n",
    "    learn(data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0401 13:22:21.294746  9800 deprecation.py:506] From c:\\ProgramData\\Anaconda3\\envs\\tf_gpu-1.15\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "W0401 13:22:21.522173  9800 deprecation.py:323] From <ipython-input-3-72dd44f793ce>:47: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    },
    {
     "ename": "SystemError",
     "evalue": "<built-in function TFE_Py_TapeWatch> returned a result with an error set",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: 'RefVariable' object has no attribute '_id'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-72dd44f793ce>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m     \u001b[0mlearn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-72dd44f793ce>\u001b[0m in \u001b[0;36mlearn\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[0moutput_layer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'out'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'reg_layer'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbiases\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'out'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[0mcost_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubtract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstock_price\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_layer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopening_price\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m     \u001b[0moptimizers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcost_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbiases\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\tf_gpu-1.15\\lib\\site-packages\\tensorflow_core\\python\\keras\\optimizer_v2\\optimizer_v2.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(self, loss, var_list, grad_loss, name)\u001b[0m\n\u001b[0;32m    313\u001b[0m     \"\"\"\n\u001b[0;32m    314\u001b[0m     grads_and_vars = self._compute_gradients(\n\u001b[1;32m--> 315\u001b[1;33m         loss, var_list=var_list, grad_loss=grad_loss)\n\u001b[0m\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\tf_gpu-1.15\\lib\\site-packages\\tensorflow_core\\python\\keras\\optimizer_v2\\optimizer_v2.py\u001b[0m in \u001b[0;36m_compute_gradients\u001b[1;34m(self, loss, var_list, grad_loss)\u001b[0m\n\u001b[0;32m    346\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mbackprop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 348\u001b[1;33m         \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    349\u001b[0m       \u001b[0mloss_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\tf_gpu-1.15\\lib\\site-packages\\tensorflow_core\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36mwatch\u001b[1;34m(self, tensor)\u001b[0m\n\u001b[0;32m    859\u001b[0m         \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwatch_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 861\u001b[1;33m         \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    862\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mtf_contextlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\tf_gpu-1.15\\lib\\site-packages\\tensorflow_core\\python\\eager\\tape.py\u001b[0m in \u001b[0;36mwatch\u001b[1;34m(tape, tensor)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mwatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m   \u001b[1;34m\"\"\"Marks this tensor to be watched by the given tape.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m   \u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTFE_Py_TapeWatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSystemError\u001b[0m: <built-in function TFE_Py_TapeWatch> returned a result with an error set"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting closing price\n",
    "#cost fn on opening price \n",
    "\n",
    "data = np.array(getData())\n",
    "data = preprocessData(data)\n",
    "num_params = data.shape[1] - 1\n",
    "\n",
    "X = data[:, 0:num_params]\n",
    "Y = data[:, num_params].reshape(-1, 1)\n",
    "\n",
    "# Split the data into training and testing sets (70/30)\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=0.30)\n",
    "train_opening_price = train_X[:, num_params - 1].reshape(-1, 1)\n",
    "test_opening_price = test_X[:, num_params - 1].reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(759, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.expand_dims(train_X[0], axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.70802696],\n",
       "       [0.70767774]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0,].reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14900, 759, 1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.reshape(train_X.shape+(1,)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14900, 759)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14900"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
