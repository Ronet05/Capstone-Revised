{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData():\n",
    "    with open('process/process_file_3.csv') as csv_file:\n",
    "        reader = csv.reader(csv_file)\n",
    "        data = list(reader)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def preprocessData(data):\n",
    "    one_hot_encoder = preprocessing.OneHotEncoder()\n",
    "\n",
    "    processed_data = one_hot_encoder.fit_transform(data[:, 0:2]).toarray()\n",
    "    processed_data = np.append(processed_data, data[:, 2:6], 1)\n",
    "\n",
    "    processed_data = preprocessing.normalize(processed_data)\n",
    "    np.random.shuffle(processed_data)\n",
    "\n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn(data):\n",
    "    data = preprocessData(data)\n",
    "    num_params = data.shape[1] - 1\n",
    "\n",
    "    X = data[:, 0:num_params]\n",
    "    Y = data[:, num_params].reshape(-1, 1)\n",
    "\n",
    "    # Split the data into training and testing sets (70/30)\n",
    "    train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=0.30)\n",
    "    train_opening_price = train_X[:, num_params - 1].reshape(-1, 1)\n",
    "    test_opening_price = test_X[:, num_params - 1].reshape(-1, 1)\n",
    "    \n",
    "    # Get the initial stock prices for computing the relative cost\n",
    "    stock_data = tf.placeholder(tf.float32, [None, num_params])\n",
    "    opening_price = tf.placeholder(tf.float32, [None, 1])\n",
    "    stock_price = tf.placeholder(tf.float32, [None, 1])\n",
    "\n",
    "    # Number of neurons in the hidden layer\n",
    "    n_hidden_1 = 3\n",
    "    n_hidden_2 = 3\n",
    "\n",
    "    weights = {\n",
    "        'out': tf.Variable(tf.random_normal([n_hidden_2, 1]))\n",
    "    }\n",
    "    biases = {\n",
    "        'out': tf.Variable(tf.random_normal([1]))\n",
    "    }\n",
    "\n",
    "    # Implement dropout to reduce overfitting\n",
    "    keep_prob_input = tf.placeholder(tf.float32)\n",
    "    keep_prob_hidden = tf.placeholder(tf.float32)\n",
    "\n",
    "    # Hidden layers\n",
    "    model = tf.keras.models.Sequential([tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape = ()),\n",
    "                                       tf.keras.layers.MaxPool2D(2,2),\n",
    "                                       tf.keras.layers.Conv2D(64, (3,3), activation = 'relu'),\n",
    "                                       tf.keras.layers.MaxPool2D(2,2),\n",
    "                                       tf.keras.layers.Dense(5, activation = 'relu'),\n",
    "                                       tf.keras.layers.Dropout(0.5),\n",
    "                                       tf.keras.layers.Dense(5, activation = 'relu'),\n",
    "                                       tf.keras.layers.Dropout(0.4),\n",
    "                                       ])\n",
    "    \n",
    "    \n",
    "    layer_1 = slim.fully_connected(stock_data, n_hidden_1, biases_initializer=None, activation_fn=tf.nn.relu)\n",
    "    layer_1_dropout = tf.nn.dropout(layer_1, keep_prob_hidden)\n",
    "    layer_2 = slim.fully_connected(input_dropout, n_hidden_1, biases_initializer=None, activation_fn=tf.nn.relu)\n",
    "    layer_2_dropout = tf.nn.dropout(layer_2, keep_prob_hidden)\n",
    "    # regression  layer = (w'x+b)\n",
    "\n",
    "    output_layer = tf.add(tf.matmul(layer_2_dropout, weights['out']), biases['out'])\n",
    "\n",
    "    learning_rate = 1e-4\n",
    "    cost_function = tf.reduce_mean(tf.pow(tf.div(tf.subtract(stock_price, output_layer), opening_price), 2))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost_function)\n",
    "\n",
    "    last_cost = 0\n",
    "    tolerance = 1e-6\n",
    "    epochs = 1\n",
    "    max_epochs = 15000\n",
    "\n",
    "    config = tf.ConfigProto(log_device_placement = True)\n",
    "    sess = tf.Session(config=config)\n",
    "    with sess:\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "\n",
    "        history = []\n",
    "        while True:\n",
    "            sess.run(optimizer,\n",
    "                     feed_dict={stock_data: train_X, opening_price: train_opening_price, stock_price: train_Y,\n",
    "                                keep_prob_input: 0.8, keep_prob_hidden: 0.5})\n",
    "\n",
    "            if epochs % 100 == 0:\n",
    "                cost = sess.run(cost_function, feed_dict={stock_data: train_X, opening_price: train_opening_price,\n",
    "                                                          stock_price: train_Y, keep_prob_input: 0.8,\n",
    "                                                          keep_prob_hidden: 0.5})\n",
    "                history.append(cost)\n",
    "                print(\"Epoch: %d: Error: %f\" % (epochs, cost))\n",
    "\n",
    "                if abs(cost - last_cost) <= tolerance or epochs > max_epochs:\n",
    "                    print(\"Converged.\")\n",
    "                    break\n",
    "                last_cost = cost\n",
    "\n",
    "            epochs += 1\n",
    "\n",
    "        print(\"Test error: \", sess.run(cost_function, feed_dict={stock_data: test_X, opening_price: test_opening_price,\n",
    "                                                                 stock_price: test_Y, keep_prob_input: 1.0,\n",
    "                                                                 keep_prob_hidden: 1.0}))\n",
    "        test_results = sess.run(output_layer, feed_dict={stock_data: test_X, stock_price: test_Y, keep_prob_input: 1.0,\n",
    "                                                         keep_prob_hidden: 1.0})\n",
    "\n",
    "    avg_perc_error = 0\n",
    "    max_perc_error = 0\n",
    "    mei = 0\n",
    "    for i in range(len(test_Y)):\n",
    "        actual_change = abs(test_Y[i][0] - test_X[i][num_params - 1]) / test_X[i][num_params - 1]\n",
    "        predicted_change = abs(test_results[i][0] - test_X[i][num_params - 1]) / test_X[i][num_params - 1]\n",
    "        delta = abs(actual_change - predicted_change)\n",
    "        avg_perc_error = avg_perc_error + delta\n",
    "        if delta > max_perc_error:\n",
    "            max_perc_error = delta\n",
    "            mei = i\n",
    "\n",
    "    avg_perc_error = (avg_perc_error * 100) / len(test_Y)\n",
    "    max_perc_error *= 100\n",
    "    print(\"Maximum percentage error: %f\\nAverage percentage error: %f\\n\" % (max_perc_error, avg_perc_error))\n",
    "\n",
    "\n",
    "def main():\n",
    "    data = np.array(getData())\n",
    "    learn(data)\n",
    "\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
